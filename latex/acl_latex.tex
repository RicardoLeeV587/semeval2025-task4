% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{longtable}
\usepackage{placeins}

\usepackage{needspace}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% \usepackage{multirow}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{iShumei-Chinchunmei at SemEval-2025 Task 4: A balanced forgetting and retention multi-task framework using effective unlearning loss}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
  Yujian Sun\textsuperscript{1},
  Tian Li\textsuperscript{2}
\\
  \textsuperscript{1}Shumei AI Research Institute, Beijing, China\\
  \textsuperscript{2}School of Computing, Newcastle University, Newcastle upon Tyne, UK
\\
  \texttt{sunyujian@ishumei.com}\\
  \texttt{t.li56@newcastle.ac.uk}
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}

%本文描述了我们在SemEval-2025任务4中的解决方案，描述了一种用于解决有限资源下用于大模型unlearning sensitive datasets的监督微调方法。我们的方法集成了多任务学习、梯度干扰以及数据增强。通过这种方法，我们的方法在部分任务中表现优异。此外，通过消融实验和结果分析我们发现了单纯的监督微调在unlearning sensitive datasets in LLMs中可能存在的一些问题。

% This paper presents our solution for SemEval-2025 Task 4, introducing a supervised fine-tuning method for unlearning sensitive data in large language models (LLMs) under resource constraints. Our approach combines multi-task learning, gradient interference, and data augmentation, achieving promising results across several tasks. Additionally, through extensive ablation experiments and detailed result analysis, we identify potential issues that arise when relying solely on supervised fine-tuning for unlearning sensitive data.

% 随着LLM逐渐的流行，如何使LLM忘记在训练期间记住的非合规数据也越来越受人关注。Machine Unlearning便是研究如何在有限的资源内抹除LLM所记住的敏感信息。为了推进对这个领域的研究，SemEval2025-task11 "Unlearning sensitive content from Large Language Models" 提出了包含三个unlearning datasets，并通过评估遗忘的效果与标准能力的保持来构建Unlearning的benchmark。在我们的工作中，我们提出了一种更加可控的遗忘Loss： EUL，并将其同不同技术方案搭配以探索更高效可控的Unlearning 训练方式。最终，我们的系统在leaderboard上排名第五。

As the Large Language Model (LLM) gains widespread adoption, increasing attention has been given to the challenge of making LLM forget non-compliant data memorized during its pre-training. Machine Unlearning focuses on efficiently erasing sensitive information from LLM under limited computational resources. To advance research in this area, SemEval 2025 Task 11: "Unlearning Sensitive Content from Large Language Models" introduces three unlearning datasets and establishes a benchmark by evaluating both forgetting effectiveness and the preservation of standard capabilities. In this work, we propose a more controllable forgetting loss, Effective Unlearning Loss, and explore its integration with various techniques to achieve more efficient and controlled unlearning. Our system ultimately ranked 5th on the competition leaderboard.

\end{abstract}

\section{Introduction}
\iffalse
%大语言模型（LLMs）在自然语言理解和生成方面表现出了卓越的性能。然而，由于它们是基于大量数据进行训练的，它们可能会无意中保留并重复敏感信息，从而引发关于隐私和合规性的严重担忧。SemEval-2025任务4：“从大语言模型中遗忘敏感内容”旨在旨在通过开发一个全面的评估挑战来弥补缺乏强大的评估框架来评估这些反学习策略的准确性的问题。对于确保伦理的AI部署并符合隐私法规至关重要。该任务以英语进行，评估将考虑任务特定的重复率、成员推断攻击（MIA）得分和MMLU基准性能，以衡量模型在遗忘指定内容的同时，保持其更广泛的语言和推理能力的有效性。

%八股文
%第一段讲任务是什么，存在什么问题，比赛为了解决什么问题。介绍数据集，这份数据集提出、鼓励研究人员推动unlearning的贡献。
%第二段，我们参加了这次比赛，在比赛中我们干了个什么事，要写一个原因，我们尝试了一些基于梯度和机遇数据增强的方案，为什么我们采用这些方案。我们做了什么适配，对梯度做了什么改动。high leval
%我们的贡献如下：1.2.3.，
%1.第一个一定是用了什么技术，全称+简单做法。
%2.高角度的high level的增益有什么，通过详细的实验，我们发现xxx对我们最终的效果有贡献，这揭示了xxxx的有效性。
%3.要不要补充更多的贡献，我们最终的榜单排在第几。


Large Language Models (LLMs) have demonstrated remarkable performance in natural language understanding and generation. However, as they are trained on vast amounts of data, they may unintentionally retain and regurgitate sensitive information, posing serious concerns regarding privacy and compliance. 
SemEval-2025 Task 4: "Unlearning Sensitive Content from Large Language Models"
(\citep{ramakrishna2025lumellmunlearningmultitask})
seeks to address the lack of a robust evaluation framework for assessing the accuracy of unlearning strategies by providing a comprehensive evaluation challenge. 
This task is crucial for ensuring the ethical deployment of AI and compliance with privacy regulations.
Conducted in English, the evaluation will consider metrics such as task-specific regurgitation rates, Membership Inference Attack (MIA) scores, and MMLU benchmark performance, to measure how effectively the model forgets specified content while retaining its broader language understanding and reasoning abilities.\par

%我们的系统采用了多任务学习方法，并结合梯度干扰技术和数据增强来改善反学习过程。具体来说，我们引入了多个训练目标，以控制模型如何处理保留数据和遗忘数据。对于需要保留的数据，我们应用监督微调（Supervised Fine-Tuning，SFT）损失，确保模型保持其一般知识。对于必须遗忘的数据，我们采用了梯度干扰，一种灵感来源于梯度上升的Gradient Ascent损失函数。此外，我们也对将类似I don't know的文本替换遗忘数据的输出文本的方案进行了尝试。为了增强模型在不同输入长度和上下文中的鲁棒性，我们应用数据增强技术，将答案拆分为句子并重新组合，生成多样化的训练实例。这一策略确保模型在有效学习遗忘内容的同时，保持其在非敏感数据上的表现。

Our system adopts a multi-task learning approach combined with gradient interference techniques and data augmentation to enhance the unlearning process. Specifically, we introduce multiple training objectives to regulate how the model handles retained and forgotten data. 
For data that must be retained, we apply Supervised Fine-Tuning (SFT) loss to ensure the model preserves its general knowledge. 
For data that needs to be forgotten, we implement gradient interference, inspired by the Gradient Ascent loss function. Additionally, we experiment with replacing the outputs of forgotten data with negative responses resembling  "I don’t know." (\citet{choi2024snap};\citet{shi2024ulmr}) 
To improve the model's robustness across varying input lengths and contexts, we apply data augmentation techniques, such as breaking answers into sentences and recombining them to generate diverse training instances. 
This strategy ensures that the model effectively learns which content to forget while maintaining its performance on non-sensitive data.

%我们的系统在SemEval-2025任务4中，基于7B模型的效果排名第五。实验结果表明，我们的方法能够在实现选择性遗忘的同时，保持良好的整体性能，并且具有较高的易用性。然而，1B模型的实验表现揭示了我们的方法对参数和模型规模具有一定的敏感性。同时，我们还发现，在处理多种类型的数据时，尤其是在平衡短文本与长文本的遗忘效果方面，我们的方法在遗忘的有效性上存在一定差异。此外，通过消融实验，我们深入探讨了损失函数和数据增强策略的作用，进一步验证了它们在实现可控遗忘中的重要性。我们的研究为大语言模型的隐私保护提供了新的思路，提出了一种简便易用的选择性遗忘方法，并为未来机器反学习技术的发展提供了实验依据。详细的代码和实验记录可通过以下链接获取：https://github.com/yizhiai1994/CCM_at_semeval2025task4。
Our system ranked fifth in SemEval-2025 Task 4 based on the 7B model. 
Experimental results show that our approach is capable of achieving selective forgetting while maintaining strong overall performance and demonstrating high usability. 
However, experiments with the 1B model revealed that our method is sensitive to both model parameters and scale. 
Additionally, we observed that when handling diverse types of data, particularly in balancing the forgetting effectiveness between short and long texts, there is some variation in the effectiveness of forgetting.
Furthermore, through ablation studies, we thoroughly examined the role of the loss functions and data augmentation strategies, further validating their importance in achieving controlled forgetting. 
Our research provides new insights into privacy protection for large language models, proposing a simple and user-friendly method for selective forgetting and offering experimental evidence for the future development of machine unlearning techniques. 
Detailed code and experimental records are available at the following link: https://github.com/yizhiai1994/CCM\_at\_semeval\\2025task4.

\fi

% 大型语言模型（LLMs）在各种自然语言任务中取得了巨大成功，但它会记住训练集中的敏感信息。因此不法分子可以通过特殊手段恢复出训练语料的敏感信息，从而带来隐私曝光，版权泄露等潜在风险。机器遗忘（Machine Unlearning）正是为了解决这一问题而新兴的研究领域。其核心挑战包括（1）。 在遗忘的同时依然保留不该遗忘的重要信息与能力（2）不同数据类型的适应性（3）计算成本与效率。 

Large Language Models (LLMs) have achieved remarkable success across various natural language tasks. However, LLMs tend to memorize sensitive information from their training data, posing potential risks such as privacy breaches and copyright violations \cite{wang2024machine}. Malicious attacker can exploit this vulnerability to extract confidential content, leading to unintended exposure. Machine Unlearning has emerged as a research field to address this issue, focusing on the following core challenges\cite{qu2023learn, li2025machine}:(1) Preserving essential information and capabilities while ensuring the removal of targeted data. (2) Adapting to different data types. (3) Balancing computational cost and efficiency.

% SemEVAL2025 Task 4 提出了“Unlearning sensitive content from Large Language Models” 挑战。其目的在于提出一个健全的benchmark来衡量LLM遗忘策略的有效性。其包含三类数据：长篇创意文档，简短个人信息，公开人物传记。每类数据都有预先划定的“遗忘集”（Forget set）和“保留集”（Retain set）。其不仅评估遗忘的效果，还会在MMLU Benchmark上评估通用能力的损失。此外，为了鼓励大家平衡计算成本与最终效果，该比赛的评估还会限制提交方案的运行时间。

SemEval-2025 Task 4 introduce the challenge "Unlearning Sensitive Content from Large Language Models," aiming to establish a robust benchmark for evaluating the effectiveness of unlearning strategies in LLMs \cite{ramakrishna2025lumellmunlearningmultitask}. The task encompasses three data categories: long-form synthetic creative documents with different genres, short form synthetic biographies containing personal information, and real documents sampled from the target model’s training dataset. Each dataset includes predefined "Forget" and "Retain" sets, and encompasses two evaluation tasks: sentence completion and question-answering. The evaluation not only assesses the success of unlearning but also measures the impact on general capabilities using the MMLU Benchmark. To encourage a balance between computational efficiency and performance, the organizers also impose runtime constraints on submitted solutions.

% 在本次比赛中，我们提出一种方案：Gradient Contrastive Interference Learning (EUL). 通过扰动模型对于被遗忘数据的梯度来达到遗忘相关知识的作用。同时为了进一步确保遗忘的可控性，我们将其同标准SFT流程融合成了一个多任务学习目标，并且尝试了各种数据处理与增强方案。

In this competition, we propose Effective Unlearning Loss (EUL). This aims to erase knowledge related to the data to be forgotten by perturbing the model's gradients during training. We integrate this technique with the standard Supervised Fine-Tuning (SFT) process into a multi-task learning paradigm to ensure controllable unlearning. Additionally, various data processing and augmentation strategies \cite{choi2024snap, shi2024ulmr} are explored to see their impact on the final performance.

% 我们的贡献如下：
% 1. 我们提出了EUL。该技术通过比对当前输出与需要被遗忘的信息的相似性来控制损失的大小，从而实现针对模型可控的遗忘。同时我们还利用多任务学习的方案，让模型在不该遗忘的数据同步进行SFT。
% 2. 我们详细的探索了我们的方案在不同配置，不同数据处理的条件下的效果。这为后续研究提供了可靠的参考依据
% 3. 我们的方案在最终榜单上排名第5，充分证明了方案的有效性。
\begin{figure*}[!t]
  \centering
  \includegraphics[width=2\columnwidth]{论文图.png} 
  \caption{The Overview of Our System.}
  \label{fig:overview}
\end{figure*}

Our contributions are as follows:
\begin{itemize}
	\item \textbf{Introduction of EUL}: This loss is the multiplicative inverse of the original SFT loss. Its inverse property makes it effective in making LLM forget the target knowledge. We integrate it into a multi-task learning paradigm, allowing the model to perform SFT on data that should be retained and EUL on data that should be erased concurrently.
	\item \textbf{Comprehensive Exploration}: We thoroughly investigate the performance of our method under different configurations and data processing/augmentation settings, providing a reliable reference for future research.
	\item \textbf{Competitive Performance}: Our approach secures 5th place on the final leaderboard, demonstrating its effectiveness.
\end{itemize}


\section{Background}
%每个工作不要超过两行半
%最好基于前序经验，解决什么工作。

%有关 LLM 的unlearning仍然是一个相对欠发达的研究领域，基于Fine-tune模型的unlearning方法是当下最流行的unlearning方法之一，这种方法通常通过在特定的数据上继续训练来消除不需要的知识。
Research on knowledge unlearning in large language models (LLMs) is an emerging field, with fine-tuning-based unlearning being one of the most common method. This involves retraining the model on datasets containing specific target knowledge to weaken its memory of the unwanted information.

%一种直觉的方法是使用类似梯度上升的方法作为损失直接对需要消除的知识进行训练。
One intuitive unlearning method involves gradient ascent on the forget data, which increases the loss on that data to force the model to forget specified knowledge. However, this often leads to optimization instability and poor performance. To solve this, \citet{veldanda2024llm} propose a comprehensive training approach that involves gradient ascent, standard gradient descent on the forget dataset, and minimizing KL divergence to maintain the model’s performance on retained knowledge. Similarly, \citet{jang2022knowledge} introduces a gradual gradient ascent approach, which stabilizes the unlearning process and avoids instability. 

Another unlearning method involves replacing the forgotten knowledge, such as \citet{choi2024snap} and \citet{shi2024ulmr} who replace forgotten answers with negative responses like "I don't know," while \citet{eldan2023s} uses reinforcement learning to identify and replace key phrases. However, \citet{mekala2024alternate} warns that relying solely on negative feedback for unlearning may result in non-sensical outputs and introduce privacy risks, reducing the model's effectiveness.

In response, we propose a more pragmatic approach to unlearning in LLMs that combines multi-task learning, data augmentation, and EUL to facilitate faster and more efficient knowledge forgetting under constrained resources.



\section{System Overview}

%在这次比赛中，我们着重探索了基于梯度上升思想的fine-tune方案，并进一步提出了更加可控的effective unlearning loss (EUL) 以及用于支撑EUL生效的配套数据增强方案和多任务学习框架。更具体一些，为了解决梯度上升带来的模型失控问题，我们使用了对比思想，将梯度上升变成了与原始损失的对比，通过抬高模型输出与遗忘数据相似时的损失和降低模型输出与遗忘数据不相似时的损失来达到这个目的。同时为了确保原有的知识不被遗忘，我们还引入了对原始数据进行finetune来保留对应知识。
% In this competition, we explore a fine-tuning based approach inspired by the concept of gradient ascent, and proposed a more controllable method, the Effective Unlearning Loss (EUL), along with a supporting data augmentation strategy and a multi-task learning framework to enhance the effectiveness of EUL. 
% Specifically, to address the issue of model instability caused by gradient ascent, we applied a contrastive approach by transforming gradient ascent into a contrast with the original loss function. This was achieved by increasing the loss when the model’s output is similar to the forgotten data and decreasing the loss when the model's output is dissimilar to the forgotten data. Additionally, to ensure that the model retains existing knowledge, we incorporated fine-tuning on the retain data to preserve the relevant knowledge.

In this competition, we propose the Effective Unlearning Loss (EUL), which, combined with traditional Supervised Fine-Tuning (SFT), forms a multi-task learning framework. Meanwhile, we observe a significant performance discrepancy between long and short outputs. To mitigate this issue, we incorporate data augmentation. The overall workflow is illustrated in Figure~\ref{fig:overview}.

Section~\ref{sec:EUL} provides a detailed introduction of EUL, while section~\ref{sec:MTL} demonstrates its integration with the original SFT process to enable multi-task training. Finally, section 3.3 discusses our data augmentation strategies.


%图 1(a)展示了整体的系统训练流程。3.1放EUL，3.2放多任务融合，3.3放数据增强。
% Figure 1(left) illustrates the overall training procedure of our system. In what follows, we provide detailed descriptions of the effective unlearning loss (EUL) in Section 3.1, the multi-task learning module in Section 3.2 and the data augmentation module in Section 3.3.

%为了解决融合问题，我们对于遗忘batch采用EUL，对于非遗忘采用
%EUL我们在3.1详细介绍我们数据增强细节，此外为了完成这项技术，我们还要对这份
%，对于这个数据进行了适配，提出了梯度对比干扰，
%为了解决什么问题，我们提出了什么，


% \begin{figure*}[t]
%   \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
%   \includegraphics[width=0.48\linewidth]{example-image-b}
%   \caption {A minimal working example to demonstrate how to place
%     two images side-by-side.}
% \end{figure*}



\subsection{Effective Unlearning Loss}
\label{sec:EUL}
%梯度上升由于其在遗忘知识时的强大能力\citet{veldanda2024llm}，使得他在unlearn领域被广泛研究和应用，他的强大能力得益于其可以令梯度往与被训练数据不相似的方向前进，但是这也同样会导致梯度在上升的过程中不受控制的变大。因此，为了能够同时保持令梯度往与被训练数据不相似的方向前进又不会令模型失控以实现对遗忘集信息的“反向”调整，我们设计了Effective Unlearning Loss (EUL)，他的公式如下所示：
% Gradient ascent has been widely studied and applied in the unlearning domain due to its powerful ability to forget knowledge (\citet{veldanda2024llm}). Its effectiveness stems from its ability to direct gradients away from the learned data, effectively pushing the model in directions that deviate from the original training data. However, this strength also leads to the risk of uncontrolled gradient growth during the ascent. To address this, and to simultaneously ensure that gradients move in directions that are distant from the training data without causing model instability, we design the Effective Unlearning Loss (EUL). The formula for EUL is as follows:

% 不同于梯度上升，我们重新设计了一个新的Loss： EUL， 使得其在执行梯度下降时也能达成训练模型遗忘的功能。其公式如下：

Unlike traditional gradient ascent, we redesign a novel loss function, EUL, which enables the model to achieve the forgetting effect even during gradient descent. The formulation is as follows:

%L=a*(1/L_ntp(x_input,y_output))
\begin{equation}
L_{EUL}=\alpha  \times  \frac{1}{L_{ntp}(x_{input},y_{forget})}
\end{equation}

%其中L_ntp(x_input,y_output)表示模型以遗忘集原始输出y_output作为下一个词预测目标时得到的语言建模损失，为缩放因子用于控制损失量级。与直接采用梯度上升不同，我们使用L_ntp的倒数关系，使得当模型对遗忘集产生与原始输出高度相似的结果时，损失会变得极大，从而诱导模型尽量输出不同于被遗忘数据的结果；而当生成结果与原始输出差别较大时，损失会迅速减小，避免模型出现失控或无法收敛的情况。为了保证两种损失不产生互相干扰，我们在产生每个训练batch时，batch内只包含一种损失的数据。
% where $L_{ntp}(x_{input},y_{output})$ denotes the language modeling loss when the model uses the original output $y_{output}$ of the forget set as the prediction target, and $\alpha$ is a scaling factor that regulates the magnitude of the loss. Unlike directly performing gradient ascent, we apply an inverse relationship of $L_{ntp}$. When the model generates results that closely resemble the original output in the forget set, the loss becomes very large, thereby encouraging the model to produce outputs that differ significantly from the forgotten data; conversely, when the model generates outputs that deviate significantly from the original forgotten text, the loss rapidly diminishes, preventing the model from diverging or failing to converge. To ensure these two losses do not interfere with each other, we only include one type of loss data per training batch.

% 其中L_NTP为常规SFT所使用的next token prediction loss.alpha为缩放因子。当模型输出与需要被遗忘的信息相近的分布时，该loss会变得非常大，反之则会变得很小。相比于梯度上升容易导致模型失控，该Loss更加稳定。其确保了所造成的遗忘被被控制在了安全范围内。

Here, $L_{ntp}(x_{input},y_{forget})$ represents the next-token prediction loss used in conventional SFT, and $\alpha$ is a scaling factor. When the model's output closely aligns with the distribution of the information to be forgotten, the loss increases significantly; conversely, it remains low when the output deviates from that information. Compared to gradient ascent, which can easily lead to model instability, EUL offers a more stable and effective choice, ensuring that the induced forgetting remains within a controlled and safe range.

\subsection{Multi-Task Learning}
\label{sec:MTL}
%本任务要求模型在遗忘集（需遗忘或篡改信息）和保留集（需保持正确信息）之间达到平衡，兼顾“有效遗忘”与“信息保留”。通过对比分析遗忘集与保留集的文本，我们发现两者在词汇、主题等方面高度相似，但在预测目标上截然不同。为此，我们采用了多任务学习（Multi-Task Learning, MTL）的范式，将二者统一在一个模型框架中进行训练。因此，我们定义了两项子任务：

% This task demands a balance between the forget set (where information must be erased or distorted) and the retain set (where the original knowledge must be preserved), thus requiring both “effective forgetting” and “information retention.” 
% Through comparative analyses of the forget and retain sets, we found that they overlap significantly in terms of vocabulary and topics, yet require starkly different predictive objectives. 
% Consequently, we adopt a Multi-Task Learning (MTL) paradigm that unifies both sets within a single model framework. We define two sub-tasks:

% \begin{itemize}
% 	\item \noindent\textbf{Forget-Set Task} For the data that needs to be forgotten, we use EUL to enable controlled forgetting.
% 	\item \noindent\textbf{Retain-Set Task} For the data that needs to be retained, we use the common language modeling loss, next token prediction loss, to train these data, preventing it from being forgotten during the training process.
% \end{itemize}

% 为了训练模型遗忘制定内容的同时还能保留需要保留的信息，我们设计了两个task：Forget-Set Task 和Retain-Set Task。 Forget-Set Task面向Unlearning 任务。其数据为待遗忘的数据，其Loss为EUL。Retain-set Task面向信息保留任务。其数据为不盖被遗忘的数据。其Loss为传统L_NTP. 
To enable the model to forget specified content while retaining the information we want to keep, we design two tasks: the Forget-Set Task and the Retain-Set Task.
\begin{itemize}
	\item The Forget-Set Task focuses on the unlearning objective, using data that needs to be forgotten and optimizing the model with $L_{EUL}$.
	\item The Retain-Set Task ensures information retention, leveraging non-forgotten data and employing the conventional next-token prediction loss $L_{ntp}$.
\end{itemize}

% 为了保证两个任务不产生相互干扰，我们让每个batch 数据只包含一类任务数据。通过交替训练的方式，让模型达成可控的遗忘的目标。

To prevent interference between the two tasks, each batch contains data from only one task at a time. By alternating training between these tasks, the model achieves controlled forgetting in a stable manner.



\subsection{Data Augmentation} 
\label{sec:DA}

%我们发现这次比赛中无论哪个子任务的数据都存在输出长短差异巨大的文本。并且进一步实验后，我们还发现如果直接针对这些任务进行训练，模型往往难以同时兼顾长文本和段文本的效果。具体来说，如果原始输出是短文本，那么训练后的模型往往可以很好的遗忘相关知识，而对于长文本，则训练后的模型输出与原始输出近乎没有任何不同。
% We found that in this competition, the data across all sub-tasks contained texts with significantly varying lengths. Further experiments revealed that when training directly on these tasks, the model often struggles to balance the effectiveness of forgetting for both long and short texts. Specifically, if the original output is a short text, the trained model is able to effectively forget the relevant knowledge. However, for long texts, the output from the trained model shows almost no difference from the original output.

% 我们发现本次比赛数据文本长短存在长尾现象。在进行进一步的实验后，我们发现该长尾现象会影响模型效果。比如，如果原始输出是短文本，那么unlearning后的模型可以遗忘相关知识。但是如果原始输出为长文本，则unlearning 流程可能会失败。
We observe a long-tail distribution phenomenon in output length within the competition dataset. Further experiments reveal that this imbalance adversely affects model performance. For instance, if the original output is a short text, the unlearning process effectively removes the associated knowledge. However, when the original output is a long text, the unlearning procedure may fail.

%为解决上述问题，我们提出了一种针对长文本的重新切分策略。具体而言，对于长度较长的文本，我们先将其按照上下文语义边界或句子结构进行拆分，形成多段由短到长的子文本，再分别进行数据增强处理。图 1(b) 中详细展示了长文本切分的具体过程。与初始的统一替换方法相比，该切分策略能够更好地保留不同段落或句子间的语义一致性，提升对不同长度文本的适应性。
% To address this issue, we propose a segmentation strategy tailored for long texts. 
% Concretely, for long outputs, we first split them according to punctuation, forming multiple segments from short to long. 
% We then apply data augmentation to each segment accordingly. 
% Figure 1(right) presents a detailed illustration of the segmentation process for long texts. 
% Compared to the initial blanket replacement, this segmentation strategy better preserves semantic coherence across different paragraphs or sentences, thereby improving adaptability to diverse text lengths.

% 为了解决上述问题，我们提出了一种基于重新切分的数据增强策略，以平衡长短文本分布不平衡的问题。我们将长文本按语句进行拆分，并逐步将部分输出挪到输入中从而生成更短的输出作为训练样本。该流程如图1右侧所示。该方案能很好的提升模型对不同长度文本的适应性。

To address this issue, we propose a data augmentation strategy based on re-segmentation to balance the distribution of short and long output. Specifically, we segment long output into individual sentences and incrementally move portions of the output into the input, generating shorter outputs as training samples. This process, illustrated in figure~\ref{fig:overview} right, enhances the model's adaptability to varying output lengths.

%此外，我们还尝试了论文1中提到的negative response replace方案。其通过将敏感信息替换为“I don't know”语句并训练，从而达成遗忘的目标。
In addition, we also try the negative response replace scheme mentioned in \cite{tofu2024}. It achieves the goal of forgetting by replacing sensitive information with the safety terms (for example, "I don't know") and tuning models on it.

\begin{table*}[!t]
  \centering
    \begin{tabular}{llll|llllll}
    \hline
    \multicolumn{4}{c}{\textbf{Model Component}} & \multicolumn{4}{c}{\textbf{Score}} \\ \hline
         RD & NR & DA & EUL & MIA & TAS & MMLU & Final \\ \hline
         × & O & × & × & 0.000 & 0.092 & 0.281 & 0.124 \\ \hline
         × & O & O & × & 0.000 & 0.092 & 0.278 & 0.124 \\ \hline
         O & O & × & × & 0.000 & 0.124 & 0.283 & 0.135 \\ \hline
         O & O & O & × & 0.000 & 0.137 & 0.278 & 0.138 \\ \hline
         × & × & × & O & 0.993 & 0.408 & 0.229 & 0.543 \\ \hline
         × & × & O & O & 0.989 & 0.421 & 0.229 & 0.547 \\ \hline
         O & × & × & O & 0.009 & 0.185 & 0.278 & 0.157 \\ \hline
         O & O & × & O & 0.000 & 0.095 & 0.285 & 0.127 \\ \hline
         O & × & O & O & 0.593 & 0.395 & 0.275 & 0.421 \\ \hline
         O & O & O & O & 0.035 & 0.222 & 0.279 & 0.179 \\ \hline
    \end{tabular}
  \caption{
    The main results in our experiments.
  }
  \label{tab:AS2}
\end{table*}


\begin{table*}[t]
  \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
    \hline
        EP & LR & RD & NR & DA & EUL & MIA & TAS & MMLU & Final \\ \hline
        3 & 1.00E-04 & O & × & O & O & 0.135 & 0.245 & 0.272 & 0.217 \\ \hline
        3 & 1.00E-05 & O & × & O & O & 0.000 & 0.092 & 0.280 & 0.124 \\ \hline
        3 & 1.00E-06 & O & × & O & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
        4 & 1.00E-04 & O & × & O & O & 0.215 & 0.278 & 0.270 & 0.254 \\ \hline
        4 & 1.00E-05 & O & × & O & O & 0.000 & 0.112 & 0.280 & 0.131 \\ \hline
        4 & 1.00E-06 & O & × & O & O & 0.000 & 0.092 & 0.276 & 0.122 \\ \hline
        5 & 1.00E-04 & O & × & O & O & 0.593 & 0.395 & 0.275 & 0.421 \\ \hline
        5 & 1.00E-05 & O & × & O & O & 0.001 & 0.112 & 0.279 & 0.131 \\ \hline
        5 & 1.00E-06 & O & × & O & O & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
    \end{tabular}
  \caption{
    Ablation study on hyper-parameters }
\label{tab:AS1}
\end{table*}



\section{Experiment}
%在本次任务中，我们基于 LoRA（Low-Rank Adaptation）方法对大型语言模型进行精调。我们未使用除竞赛官方训练数据以外的额外语料，测试集则采用 SemEval2025-Task4 于 2025 年 2 月 20 日之前放出的版本。所有离线实验均在配备 40GB 显存的单卡 A100 GPU 上完成，训练时长均不超过 1 小时。

% lora_para = {
%   'r': 8,
%   'alpha': 32,
%   'dropout': 0.05
% }

% In this task, we employ a LoRA approach \cite{hu2022lora} to fine-tune a large language model, and the parameters are set as follows: $r=8$, $\alpha=32$, $dropout=0.05$.
% All experiments in this paper were conducted using the dataset provided by Semeval2025 Task4\citep{ramakrishna2025lumellmunlearningmultitask}, which was released during the competition. 
% All offline experiments are conducted on a single NVIDIA A100(40 GB) GPU, and each training session is completed within one hour. 

% The final evaluation score is computed as the average of three components:

% \begin{itemize}
% \item \noindent\textbf{Task Aggregate Score} This method is used to measure the model's completion of various tasks.

% \item \noindent\textbf{Membership Inference Attack (MIA)} This metric evaluates the extent to which the relevant knowledge is preserved or effectively forgotten.

% \item \noindent\textbf{MMLU Score} This serves as a measure of whether the model’s overall linguistic capability suffers any degradation after the unlearning process.
% \end{itemize}

% 本次比赛赛方要求在两个模型上进行unlearning：OLMo-7B 和OLMo-1B。 其原始任务包含sentence completion and question-answering。为了评估unlearning的效果，赛方提出了以下四个评估指标。

% 1. Task Aggregate Score(TAS): This method is used to measure the model's completion of various tasks.
% 2. Membership Inference Attack Score (MIA): This metric evaluates the extent to which the relevant knowledge is preserved or effectively forgotten.
% 3. MMLU Score: This serves as a measure of whether the model’s overall linguistic capability suffers any degradation after the unlearning process
% 4. Final Score: The average of the previous three scores.

% 我们全方位的探索了不同技术组合对于最终unlearning效果的影响，同时还对模块和超参数进行了消融试验。其结果分别在Section5 和seciotn6中。

% 我们的所有训练均采用LoRA来微调模型。Rank，alpha和dropout分别被设置为8， 32，和0.05。 所有试验都使用1张Nvidia A100(40G)显卡，并且每个unlearning process均在1小时之内。

In this competition, the organizers require unlearning to be performed on two models: OLMo-7B and OLMo-1B \cite{groeneveld2024olmo}. The original tasks include sentence completion and question-answering. To evaluate the effectiveness of unlearning, the organizers propose the following four evaluation metrics:
\begin{itemize}
	\item \textbf{Task Aggregate Score (TAS)}: This metric measures the model's performance across various tasks.
	\item \textbf{Membership Inference Attack Score (MIA)}: This evaluates the extent to which the relevant knowledge is retained or effectively forgotten.
	\item \textbf{MMLU Score}: This measures whether the model's overall linguistic capabilities degrade after the unlearning process.
	\item \textbf{Final Score}: The average of the previous three scores.
\end{itemize}

%新增所使用的数据
%新增，给出EUL中的alpha的值

We thoroughly explore the impact of different technical combinations on the final unlearning outcome and conduct ablation studies on the modules and hyperparameters. Due to the time limit, all experiments are carried on OLMo-1B. All results presented are based on data publicly released by the organizers during the competition period. The results are presented in section~\ref{sec:Result} and section~\ref{sec:Ablation}.

All training is performed using LoRA \cite{hu2022lora} for model fine-tuning, with Rank, alpha, and dropout set to 8, 32, and 0.05, respectively. 
For EUL, $\alpha$ is set as 1. For the training hyperparameters, we use the following settings:$epoch=5$, $lr=1e-4$, and $batch=32$. All experiments are conducted on a single Nvidia A100 (40G) GPU, and each unlearning process is completed within one hour.

\section{Result}
\label{sec:Result}

%Experiment setup只写表2中的内容

%Result 5
%句子1:table2展示了我们的系统在装配了不同组件下的效果。
%句子2:其中NR、RF之类的分别指什么。
%谁高谁低，谁是最好的，用一到两句话解释好坏的原因，为什么RD和EUL要留下，为什么NR不能要
%由于计算资源的限制，在比赛结束日前，我们拿到的最好结果是倒数第二行，因此我们提交了这个方案。
%表1展示了我们使用的不同方法的组合对效果的影响。其中EUL denotes Effective Unlearning Loss, NR indicates that the original outputs for the forgotten data were replaced with negative responses, 其中 NR所使用的negative responses来自于\citep{tofu2024} , DA signifies the inclusion of data augmentation during training, RD表示对保留集的数据进行finetune, EP represents the number of epochs, and LR denotes the learning rate. 此外我们使用MIA, Task, MMLU, Final分别来指代MIA Score, Task Aggregate Score, MMLU Score以及三者取平均得到的最终得分。

Table~\ref{tab:AS2} illustrates the impact of different method combinations on performance. Here, EUL denotes Effective Unlearning Loss, NR indicates that the original outputs for the forgotten data are replaced with safety terms. DA is the inclusion of data augmentation during training, RD refers to supervised fine-tuning the data in the retain set,
% EP represents the number of epochs, and LR denotes the learning rate. Additionally, we use MIA, TAS, MMLU, and Final to refer to the MIA Score, Task Aggregate Score, MMLU Score, and the final score, which is the average of the three. Finally, in the experimental tables, 
"×" denotes the absence of the corresponding technique, while "O" indicates its application.

%从表1中可以看出，在使用EUL处理遗忘数据的同时加入数据增强和finetune retain data可以获得最高的效果，这是因为这么做可以同时兼顾不同类型任务以及不同类型的数据。而随着negative responses的加入，效果会随之下降，这可能是因为被遗忘数据同时受到两种损失的影响使得梯度难以始终沿着一个方向进行优化导致的。

% As shown in table~\ref{tab:AS2}, t
% The best performance is achieved when EUL is applied to process forgotten data, combined with data augmentation and fine-tuning the retain data. This approach is effective because it simultaneously accommodates different task types and data types. However, the inclusion of negative responses results in a decline in performance. This may be due to the limited amount of forgotten data, where the simultaneous influence of two different loss functions causes the gradients to struggle to optimize consistently in a single effective direction.

%由于计算资源的限制，在比赛结束日前，我们拿到的最好结果是表1中第8行的方案，因此我们提交了这个方案。

% Due to computational resource limitations, the best result we achieved before the competition deadline was from the eighth configuration in table~\ref{tab:AS2} (RD\&NR\&EUL). Therefore, we submitted this configuration.
% 当使用 EUL 处理遗忘数据，并结合数据增强和微调保留数据时，性能最佳。其成功的原因在于可以多任务训练框架可以很好的平衡遗忘与保留。此外我们还可以得到以下key findings

% 1. 无论采用何种技术组合，微调保留数据都是必不可少的。丢弃RD的试验会导致MMLU分数大幅下降，表明其对应的模型语言能力严重退化。
% 2. 尽管NR的加入对MMLU会有收益，但是其会损害Unlearning的效果。其原因在于数据量较小所以非常容易过拟合。相比之下EUL在MMLU和Unlearning的平衡上做的更好
% 3. DA的加入对于MIA指标有明显增益，但是会略微牺牲MMLU指标。由于最终评分为三个分数的平均，因此总体来看DA具备明显的正向收益。
The best performance is achieved when using EUL to process forgotten data while incorporating data augmentation and fine-tuning retained data. This success can be attributed to the multi-task training framework, which effectively balances forgetting and retention.
%新增, 给出了仅使用EUL以及EUL+DA虽然数值上好看，但是MMLU大幅下降，这是与竞赛目标相悖的。
Note that although the approaches employing only EUL and the combination of EUL and DA achieve relatively high scores, this performance comes at the significant compromise on the MMLU metric. 
%Such a substantial degradation implies that the intrinsic capability of the model is severely compromised, which contradicts the intended evaluation criteria of the task. Consequently, these two approaches were discarded.
Such a substantial degradation contradicts the evaluation criteria from the organizers, so we discard them.
We derive the following key findings:
\begin{itemize}
	\item Fine-tuning on retained data is essential, regardless of the chosen technique combination. Experiments omitting RD resulted in a significant drop in MMLU scores, indicating severe degradation in the model’s linguistic capabilities.
	\item Although adding NR improves MMLU, it negatively impacts the unlearning effectiveness. This is due to the small dataset size, making it highly prone to overfitting. In contrast, EUL achieves a better balance between MMLU and unlearning performance.
	\item Incorporating DA enhances the MIA metric, albeit with a slight trade-off in MMLU. However, since the final score is the average of the three metrics, DA provides an overall positive impact.
\end{itemize}

% 由于计算资源的限制，在比赛deadline之前，我们拿到的最平衡的结果是RD\&NR\&EUL。因此，我们当时提交了这个方案。

Due to computational constraints, the most balanced result we obtained before the competition deadline was (RD\&NR\&EUL). Therefore, our result on the leaderboard is (RD\&NR\&EUL) result, not our best result.

% Ablation Study
%任务系统外，我们还对如下内容进行了消融实验
%1.数据增强消融
%2.参数敏感性
%3.梯度干扰的结果
%6.1数据增强，表4表达了不同的数据增强方案对最终效果的影响，一句话总结，不能要那个RF，为什么不能要。
%6.2表xxx表达了不同的EP和LR对效果的影响
%6.3表5梯度平方的影响，我们发现平方没有用
%表3给我死，国内下午四点

%表达了EP和LR对xxx对影响，一句话总结。
%6.2

%表2删掉EP和LR，上面加个配置
\section{Ablation Study}
\label{sec:Ablation}
%针对我们的系统，我们还对EUL、finetune retain data、数据增强、参数敏感性分别进行了消融实验。并尝试了进一步扩展EUL。我们列出了一部分重要的结果，全部的消融实验结果可以在附录A种查看。

% For our system, w
% We also conducted ablation experiments on EUL, fine-tuning the retain data, data augmentation, and parameter sensitivity, and further explored the extension of EUL. We present a subset of the key results here, with the complete ablation results available in Appendix~\ref{sec:appendixA}.

We also explore the impact of different hyperparamter settings, including learning rate, epoch, and magnitude scaling of EUL. We present the results in the following sections, and attach all experiment results in the Appendix~\ref{sec:appendixA}.
\iffalse
% \subsection{梯度干扰及使用原文}
\subsection{Effective Unlearning Loss \& Fine-tune Retain Data} 

\begin{table}[h]\footnotesize
  \centering
    \begin{tabular}{l|l|l|l|l}
    \hline
        ~ & MIA & TAS & MMLU & Final \\ \hline
        NR & 0.00 & 0.09 & 0.28 & 0.12 \\ \hline
        NR\&RD & 0.00 & 0.12 & 0.28 & 0.14 \\ \hline
        EUL & 0.99 & 0.41 & 0.23 & 0.54 \\ \hline
        EUL\&RD & 0.01 & 0.19 & 0.28 & 0.16 \\ \hline
        EUL\&RD\&DA & 0.59 & 0.39 & 0.28 & 0.42 \\ \hline
        NR\&EUL\&RD\&DA & 0.02 & 0.23 & 0.28 & 0.18 \\ \hline
    \end{tabular}
  \caption{The effects of each part of the system.}
  \label{tab:accents}
\end{table}

%表2表明，无论采用哪种方法，微调保留数据都是必不可少的。通过对比微调保留数据前后的输出，我们发现省略微调保留数据会导致模型变得不可控，导致其重复生成相同的单词。这个问题也反映在 MMLU 分数上，当不使用保留数据时，MMLU 分数大幅下降，表明模型的语言能力严重恶化。此外，梯度干扰和负响应替换相关的结果表明，加入梯度干扰显着改善了遗忘效果，同时保留了模型的语言能力；然而，引入负替代会导致性能整体下降，这是由于被遗忘的数据数据量较小，难以同时支撑两个优化目标的引入。并且表4还表明了使用EUL会比negative response replacement更加有效。 

Table 1 and Table 2 indicate that fine-tuning the retain data is essential, regardless of whether EUL or negative response replacement is used. A comparison of the outputs before and after fine-tuning the retain data reveals that omitting this step results in the model becoming uncontrollable, leading to the repeated generation of the same words. This issue is also reflected in the MMLU scores, which experience a significant decline when the retain data is excluded, indicating a severe deterioration in the model's language abilities. Furthermore, the results related to EUL and negative response replacement show that incorporating EUL significantly enhances the forgetting effect while maintaining the model's linguistic capabilities. However, the introduction of negative response replacement leads to an overall decrease in performance, likely due to the limited amount of forgotten data, which makes it difficult to support both optimization objectives simultaneously. Additionally, Table 2 demonstrates that the use of EUL is more effective than negative response replacement.

% \subsection{数据增强}
\subsection{Data Augmentation} 

%通过表2的对比可以看出，随着数据增强的加入，系统的unlearn能力进一步提高，通过针对样本输出结果的分析，可以发现在加入数据扩充前，在遇到需要遗忘的知识是长回复是，几乎不存在变化，而在加入数据增强之后，这类样本可以被有效的解决。
The comparison in Table 2 shows that the incorporation of data augmentation further improves the system's unlearning capabilities. Additionally, the MMLU results demonstrate that the model’s linguistic abilities remain largely unaffected. An analysis of the model's output reveals that, prior to data augmentation, there was virtually no change when dealing with long responses that required forgetting. However, after the inclusion of data augmentation, such samples were effectively handled, resulting in significant improvements in the unlearning process.
\fi


% \subsection{参数敏感性}
\subsection{Hyper-parameters ablation}  

%表1显示了在不同参数下，我们的新方法与提交的方法的结果，可以明显看出，两种方法都对于参数非常的敏感，会随着训练的加长效果不断变好。
Table~\ref{tab:AS1} demonstrates the performance variations under different hyperparameters. Due to computational resource limitations, we are only able to test results up to a maximum of 5 epochs. However, it is evident that as the epoch number and learning rate increase, the performance increases

%新增修改，表3改名
\subsection{Amplify EUL} 
To further examine the impact of our EUL approach, we square the EUL to produce more extreme upper and lower bounds for the loss variation. However, as demonstrated in table~\ref{tab:accents}, this magnitude scaling does not yield any noticeable performance improvement.

\begin{table}[h]\footnotesize
  \centering
    \begin{tabular}{l|l|l|l|l}
    \hline
        ~ & MIA & TAS & MMLU & Final \\ \hline
        EUL & 0.59 & 0.39 & 0.28 & 0.42 \\ \hline
        EUL$^2$ & 0.39 & 0.22 & 0.28 & 0.29 \\ \hline
    \end{tabular}
  \caption{Further exploration of EUL capabilities.}
  \label{tab:accents}
\end{table}



%为了进一步探索我们的梯度干扰方法的影响，我们通过对其平方来让损失的变化上下限更加极端，表3的结果显示，损失的变化更加极端并不会带来有效的增益，我们认为这是由于过大的损失会令模型受到难以修复的破坏。


\section{Conclusion} 
% SemEval-2025 Task4的组织者推出了一个极具挑战性的Machine Unlearning数据集，包含多种不同类型数据和角度的unlearn能力评估。该数据集充分反映了Machine Unlearning当前所面临的诸多挑战。
The organizers of SemEval-2025 Task 4 introduce three Machine Unlearning datasets, design to assess unlearning capabilities from multiple perspectives and across various data types. This dataset effectively highlights the key challenges currently faced in Machine Unlearning.

% 在本次比赛中，我们提出了一种更加可控的遗忘Loss：EUL。我们将其同标准SFT 融合成多任务学习目标，确保模型遗忘的精准性并最大程度保留其通用能力。我们还为其搭配了不同的数据处理与增强策略，从而探索可控的遗忘训练。

In this competition, we propose a more controllable forgetting loss, EUL, which we integrate with standard Supervised Fine-Tuning (SFT) into a multi-task learning framework. This approach ensures precise unlearning while maximizing the retention of general capabilities. Additionally, we incorporate various data processing and augmentation strategies to further enhance controllable unlearning.

% 我们的试验证明了EUL的有效性。同时我们也highlight了Unlearning任务中标准SFT对于需要保留的数据的训练的重要性。这种遗忘-保留的平衡是Unlearning成功的关键。同时我们还为处理数据长尾问题提供了一个行之有效的数据增强解决方案。最终我们在赛方提供的leaderboard上拿到了第五名。
Our experiments demonstrate the effectiveness of EUL and underscored the critical role of standard SFT in training on retained data. Striking the right balance between forgetting and retention is essential for successful unlearning. Furthermore, we introduce an effective data augmentation solution to address the long-tail distribution in text length. Ultimately, our system ranks 5th on the official leaderboard.


% \section*{Acknowledgments}

% This document has been adapted
% by Steven Bethard, Ryan Cotterell and Rui Yan
% from the instructions for earlier ACL and NAACL proceedings, including those for
% ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya,
% ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu,
% NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
% Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan,
% NAACL 2017 by Margaret Mitchell,
% ACL 2012 by Maggie Li and Michael White,
% ACL 2010 by Jing-Shin Chang and Philipp Koehn,
% ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui,
% ACL 2005 by Hwee Tou Ng and Kemal Oflazer,
% ACL 2002 by Eugene Charniak and Dekang Lin,
% and earlier ACL and EACL formats written by several people, including
% John Chen, Henry S. Thompson and Donald Walker.
% Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only

\bibliography{custom}

% \newpage
\appendix
\onecolumn
\section{Appendix: Ablation Study}\nopagebreak[4]
% \Large\textbf{Appendix: Ablation Study}
\nopagebreak
\label{sec:appendixA}


\begin{longtable}[h]{|r|r|l|l|l|l|l|r|r|l|r|}
% First page header
\hline
\multicolumn{1}{|c|}{\textbf{EP}} & \multicolumn{1}{c|}{\textbf{LR}} & \multicolumn{1}{c|}{\textbf{RD}} & \multicolumn{1}{c|}{\textbf{NR}} & \multicolumn{1}{c|}{\textbf{DA}} & \multicolumn{1}{c|}{\textbf{EUL}} & \multicolumn{1}{c|}{\textbf{EUL2}} & \multicolumn{1}{c|}{\textbf{MIA}} & \multicolumn{1}{c|}{\textbf{TAS}} & \multicolumn{1}{c|}{\textbf{MMLU}} & \multicolumn{1}{c|}{\textbf{Final}} \\ 
\hline
\endfirsthead

% Header for subsequent pages
\hline
\multicolumn{1}{|c|}{\textbf{EP}} & \multicolumn{1}{c|}{\textbf{LR}} & \multicolumn{1}{c|}{\textbf{RD}} & \multicolumn{1}{c|}{\textbf{NR}} & \multicolumn{1}{c|}{\textbf{DA}} & \multicolumn{1}{c|}{\textbf{EUL}} & \multicolumn{1}{c|}{\textbf{EUL2}} & \multicolumn{1}{c|}{\textbf{MIA}} & \multicolumn{1}{c|}{\textbf{TAS}} & \multicolumn{1}{c|}{\textbf{MMLU}} & \multicolumn{1}{c|}{\textbf{Final}} \\
\hline
\endhead

% Footer for each page (optional)
\hline
\endfoot

% Footer for the last page
\hline
\endlastfoot
3 & 1.00E-04 & O & O & O & O & × & 0.016 & 0.207 & 0.269 & 0.164 \\ \hline
3 & 1.00E-04 & O & O & O & × & O & 0.014 & 0.095 & 0.272 & 0.127 \\ \hline
3 & 1.00E-04 & O & O & O & × & × & 0.000 & 0.127 & 0.288 & 0.138 \\ \hline
3 & 1.00E-04 & O & O & × & O & × & 0.000 & 0.096 & 0.289 & 0.128 \\ \hline
3 & 1.00E-04 & O & O & × & × & O & 0.000 & 0.092 & 0.279 & 0.124 \\ \hline
3 & 1.00E-04 & O & O & × & × & × & 0.000 & 0.094 & 0.281 & 0.125 \\ \hline
3 & 1.00E-04 & O & × & O & O & × & 0.135 & 0.245 & 0.272 & 0.217 \\ \hline
3 & 1.00E-04 & O & × & O & × & O & 0.051 & 0.109 & 0.274 & 0.145 \\ \hline
3 & 1.00E-04 & O & × & × & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-04 & O & × & × & × & O & 0.000 & 0.091 & 0.273 & 0.121 \\ \hline
3 & 1.00E-04 & × & O & O & × & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
3 & 1.00E-04 & × & O & × & O & × & 0.024 & 0.099 & 0.273 & 0.132 \\ \hline
3 & 1.00E-04 & × & O & × & × & × & 0.000 & 0.092 & 0.278 & 0.123 \\ \hline
3 & 1.00E-04 & × & × & O & O & × & 0.996 & 0.424 & 0.229 & 0.550 \\ \hline
3 & 1.00E-04 & × & × & O & × & O & 0.000 & 0.092 & 0.281 & 0.124 \\ \hline
3 & 1.00E-04 & × & × & × & O & × & 0.982 & 0.404 & 0.229 & 0.539 \\ \hline
3 & 1.00E-04 & × & × & × & × & O & 0.940 & 0.395 & 0.246 & 0.527 \\ \hline
3 & 1.00E-05 & O & O & O & O & × & 0.000 & 0.092 & 0.274 & 0.122 \\ \hline
3 & 1.00E-05 & O & O & O & × & O & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
3 & 1.00E-05 & O & O & O & × & × & 0.000 & 0.092 & 0.274 & 0.122 \\ \hline
3 & 1.00E-05 & O & O & × & O & × & 0.000 & 0.091 & 0.273 & 0.121 \\ \hline
3 & 1.00E-05 & O & O & × & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-05 & O & O & × & × & × & 0.000 & 0.091 & 0.272 & 0.121 \\ \hline
3 & 1.00E-05 & O & × & O & O & × & 0.000 & 0.092 & 0.280 & 0.124 \\ \hline
3 & 1.00E-05 & O & × & O & × & O & 0.000 & 0.112 & 0.277 & 0.130 \\ \hline
3 & 1.00E-05 & O & × & × & O & × & 0.000 & 0.094 & 0.281 & 0.125 \\ \hline
3 & 1.00E-05 & O & × & × & × & O & 0.000 & 0.093 & 0.278 & 0.124 \\ \hline
3 & 1.00E-05 & × & O & O & × & × & 0.000 & 0.163 & 0.270 & 0.144 \\ \hline
3 & 1.00E-05 & × & O & × & O & × & 0.000 & 0.091 & 0.273 & 0.121 \\ \hline
3 & 1.00E-05 & × & O & × & × & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-05 & × & × & O & O & × & 0.300 & 0.192 & 0.265 & 0.252 \\ \hline
3 & 1.00E-05 & × & × & O & × & O & 0.000 & 0.092 & 0.280 & 0.124 \\ \hline
3 & 1.00E-05 & × & × & × & O & × & 0.000 & 0.093 & 0.279 & 0.124 \\ \hline
3 & 1.00E-05 & × & × & × & × & O & 0.000 & 0.093 & 0.278 & 0.124 \\ \hline
3 & 1.00E-06 & O & O & O & O & × & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
3 & 1.00E-06 & O & O & O & × & O & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
3 & 1.00E-06 & O & O & O & × & × & 0.000 & 0.092 & 0.274 & 0.122 \\ \hline
3 & 1.00E-06 & O & O & × & O & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
3 & 1.00E-06 & O & O & × & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-06 & O & O & × & × & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
3 & 1.00E-06 & O & × & O & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-06 & O & × & O & × & O & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
3 & 1.00E-06 & O & × & × & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-06 & O & × & × & × & O & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
3 & 1.00E-06 & × & O & O & × & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
3 & 1.00E-06 & × & O & × & O & × & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
3 & 1.00E-06 & × & O & × & × & × & 0.000 & 0.092 & 0.274 & 0.122 \\ \hline
3 & 1.00E-06 & × & × & O & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-06 & × & × & O & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-06 & × & × & × & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
3 & 1.00E-06 & × & × & × & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
4 & 1.00E-04 & O & O & O & O & × & 0.028 & 0.224 & 0.267 & 0.173 \\ \hline
4 & 1.00E-04 & O & O & O & × & O & 0.021 & 0.224 & 0.275 & 0.173 \\ \hline
4 & 1.00E-04 & O & O & O & × & × & 0.000 & 0.127 & 0.285 & 0.137 \\ \hline
4 & 1.00E-04 & O & O & × & O & × & 0.000 & 0.096 & 0.289 & 0.128 \\ \hline
4 & 1.00E-04 & O & O & × & × & O & 0.000 & 0.094 & 0.281 & 0.125 \\ \hline
4 & 1.00E-04 & O & O & × & × & × & 0.000 & 0.128 & 0.281 & 0.136 \\ \hline
4 & 1.00E-04 & O & × & O & O & × & 0.215 & 0.278 & 0.270 & 0.254 \\ \hline
4 & 1.00E-04 & O & × & O & × & O & 0.219 & 0.165 & 0.274 & 0.219 \\ \hline
4 & 1.00E-04 & O & × & × & O & × & 0.001 & 0.093 & 0.278 & 0.124 \\ \hline
4 & 1.00E-04 & O & × & × & × & O & 0.000 & 0.142 & 0.272 & 0.138 \\ \hline
4 & 1.00E-04 & × & O & O & × & × & 0.000 & 0.090 & 0.271 & 0.121 \\ \hline
4 & 1.00E-04 & × & O & × & O & × & 0.048 & 0.107 & 0.272 & 0.142 \\ \hline
4 & 1.00E-04 & × & O & × & × & × & 0.000 & 0.092 & 0.285 & 0.126 \\ \hline
4 & 1.00E-04 & × & × & O & O & × & 0.993 & 0.423 & 0.229 & 0.548 \\ \hline
4 & 1.00E-04 & × & × & O & × & O & 0.000 & 0.092 & 0.289 & 0.127 \\ \hline
4 & 1.00E-04 & × & × & × & O & × & 0.989 & 0.406 & 0.229 & 0.541 \\ \hline
4 & 1.00E-04 & × & × & × & × & O & 0.945 & 0.397 & 0.246 & 0.529 \\ \hline
4 & 1.00E-05 & O & O & O & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
4 & 1.00E-05 & O & O & O & × & O & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
4 & 1.00E-05 & O & O & O & × & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
4 & 1.00E-05 & O & O & × & O & × & 0.000 & 0.113 & 0.274 & 0.129 \\ \hline
4 & 1.00E-05 & O & O & × & × & O & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
4 & 1.00E-05 & O & O & × & × & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
4 & 1.00E-05 & O & × & O & O & × & 0.000 & 0.112 & 0.280 & 0.131 \\ \hline
4 & 1.00E-05 & O & × & O & × & O & 0.000 & 0.122 & 0.278 & 0.133 \\ \hline
4 & 1.00E-05 & O & × & × & O & × & 0.000 & 0.093 & 0.280 & 0.124 \\ \hline
4 & 1.00E-05 & O & × & × & × & O & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
4 & 1.00E-05 & × & O & O & × & × & 0.000 & 0.147 & 0.270 & 0.139 \\ \hline
4 & 1.00E-05 & × & O & × & O & × & 0.000 & 0.177 & 0.274 & 0.150 \\ \hline
4 & 1.00E-05 & × & O & × & × & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
4 & 1.00E-05 & × & × & O & O & × & 0.469 & 0.248 & 0.258 & 0.325 \\ \hline
4 & 1.00E-05 & × & × & O & × & O & 0.000 & 0.114 & 0.281 & 0.132 \\ \hline
4 & 1.00E-05 & × & × & × & O & × & 0.002 & 0.196 & 0.280 & 0.160 \\ \hline
4 & 1.00E-05 & × & × & × & × & O & 0.000 & 0.173 & 0.280 & 0.151 \\ \hline
4 & 1.00E-06 & O & O & O & O & × & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
4 & 1.00E-06 & O & O & O & × & O & 0.000 & 0.092 & 0.278 & 0.123 \\ \hline
4 & 1.00E-06 & O & O & O & × & × & 0.000 & 0.092 & 0.274 & 0.122 \\ \hline
4 & 1.00E-06 & O & O & × & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
4 & 1.00E-06 & O & O & × & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
4 & 1.00E-06 & O & O & × & × & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
4 & 1.00E-06 & O & × & O & O & × & 0.000 & 0.092 & 0.276 & 0.122 \\ \hline
4 & 1.00E-06 & O & × & O & × & O & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
4 & 1.00E-06 & O & × & × & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
4 & 1.00E-06 & O & × & × & × & O & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
4 & 1.00E-06 & × & O & O & × & × & 0.000 & 0.091 & 0.273 & 0.121 \\ \hline
4 & 1.00E-06 & × & O & × & O & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
4 & 1.00E-06 & × & O & × & × & × & 0.000 & 0.092 & 0.274 & 0.122 \\ \hline
4 & 1.00E-06 & × & × & O & O & × & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
4 & 1.00E-06 & × & × & O & × & O & 0.000 & 0.092 & 0.276 & 0.122 \\ \hline
4 & 1.00E-06 & × & × & × & O & × & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
4 & 1.00E-06 & × & × & × & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
5 & 1.00E-04 & O & O & O & O & × & 0.036 & 0.223 & 0.279 & 0.179 \\ \hline
5 & 1.00E-04 & O & O & O & × & O & 0.022 & 0.226 & 0.279 & 0.175 \\ \hline
5 & 1.00E-04 & O & O & O & × & × & 0.000 & 0.125 & 0.280 & 0.135 \\ \hline
5 & 1.00E-04 & O & O & × & O & × & 0.000 & 0.095 & 0.286 & 0.127 \\ \hline
5 & 1.00E-04 & O & O & × & × & O & 0.000 & 0.096 & 0.287 & 0.127 \\ \hline
5 & 1.00E-04 & O & O & × & × & × & 0.000 & 0.123 & 0.279 & 0.134 \\ \hline
5 & 1.00E-04 & O & × & O & O & × & 0.593 & 0.395 & 0.275 & 0.421 \\ \hline
5 & 1.00E-04 & O & × & O & × & O & 0.387 & 0.221 & 0.276 & 0.295 \\ \hline
5 & 1.00E-04 & O & × & × & O & × & 0.005 & 0.194 & 0.275 & 0.158 \\ \hline
5 & 1.00E-04 & O & × & × & × & O & 0.001 & 0.147 & 0.271 & 0.140 \\ \hline
5 & 1.00E-04 & × & O & O & × & × & 0.000 & 0.093 & 0.278 & 0.124 \\ \hline
5 & 1.00E-04 & × & O & × & O & × & 0.010 & 0.095 & 0.276 & 0.127 \\ \hline
5 & 1.00E-04 & × & O & × & × & × & 0.000 & 0.092 & 0.281 & 0.124 \\ \hline
5 & 1.00E-04 & × & × & O & O & × & 0.989 & 0.421 & 0.229 & 0.547 \\ \hline
5 & 1.00E-04 & × & × & O & × & O & 0.000 & 0.092 & 0.291 & 0.128 \\ \hline
5 & 1.00E-04 & × & × & × & O & × & 0.991 & 0.407 & 0.229 & 0.543 \\ \hline
5 & 1.00E-04 & × & × & × & × & O & 0.947 & 0.396 & 0.240 & 0.528 \\ \hline
5 & 1.00E-05 & O & O & O & O & × & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
5 & 1.00E-05 & O & O & O & × & O & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
5 & 1.00E-05 & O & O & O & × & × & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
5 & 1.00E-05 & O & O & × & O & × & 0.000 & 0.180 & 0.276 & 0.152 \\ \hline
5 & 1.00E-05 & O & O & × & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
5 & 1.00E-05 & O & O & × & × & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
5 & 1.00E-05 & O & × & O & O & × & 0.001 & 0.112 & 0.279 & 0.131 \\ \hline
5 & 1.00E-05 & O & × & O & × & O & 0.000 & 0.112 & 0.277 & 0.130 \\ \hline
5 & 1.00E-05 & O & × & × & O & × & 0.000 & 0.093 & 0.280 & 0.125 \\ \hline
5 & 1.00E-05 & O & × & × & × & O & 0.000 & 0.114 & 0.276 & 0.130 \\ \hline
5 & 1.00E-05 & × & O & O & × & × & 0.000 & 0.090 & 0.270 & 0.120 \\ \hline
5 & 1.00E-05 & × & O & × & O & × & 0.000 & 0.201 & 0.273 & 0.158 \\ \hline
5 & 1.00E-05 & × & O & × & × & × & 0.000 & 0.147 & 0.272 & 0.140 \\ \hline
5 & 1.00E-05 & × & × & O & O & × & 0.569 & 0.281 & 0.257 & 0.369 \\ \hline
5 & 1.00E-05 & × & × & O & × & O & 0.000 & 0.125 & 0.280 & 0.135 \\ \hline
5 & 1.00E-05 & × & × & × & O & × & 0.141 & 0.138 & 0.273 & 0.184 \\ \hline
5 & 1.00E-05 & × & × & × & × & O & 0.002 & 0.194 & 0.279 & 0.158 \\ \hline
5 & 1.00E-06 & O & O & O & O & × & 0.000 & 0.092 & 0.276 & 0.123 \\ \hline
5 & 1.00E-06 & O & O & O & × & O & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
5 & 1.00E-06 & O & O & O & × & × & 0.000 & 0.092 & 0.273 & 0.122 \\ \hline
5 & 1.00E-06 & O & O & × & O & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
5 & 1.00E-06 & O & O & × & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
5 & 1.00E-06 & O & O & × & × & × & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
5 & 1.00E-06 & O & × & O & O & × & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
5 & 1.00E-06 & O & × & O & × & O & 0.000 & 0.092 & 0.278 & 0.123 \\ \hline
5 & 1.00E-06 & O & × & × & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
5 & 1.00E-06 & O & × & × & × & O & 0.000 & 0.091 & 0.274 & 0.122 \\ \hline
5 & 1.00E-06 & × & O & O & × & × & 0.000 & 0.091 & 0.273 & 0.121 \\ \hline
5 & 1.00E-06 & × & O & × & O & × & 0.000 & 0.091 & 0.273 & 0.122 \\ \hline
5 & 1.00E-06 & × & O & × & × & × & 0.000 & 0.092 & 0.274 & 0.122 \\ \hline
5 & 1.00E-06 & × & × & O & O & × & 0.000 & 0.092 & 0.277 & 0.123 \\ \hline
5 & 1.00E-06 & × & × & O & × & O & 0.000 & 0.092 & 0.276 & 0.122 \\ \hline
5 & 1.00E-06 & × & × & × & O & × & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline
5 & 1.00E-06 & × & × & × & × & O & 0.000 & 0.092 & 0.275 & 0.122 \\ \hline


\caption{Ablation Study Results}
\label{sec:tab_app_ablation}
\end{longtable}
% \caption{Ablation Study Results}
\end{document}
